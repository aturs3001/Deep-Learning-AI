{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Getting Started with Deep Learning Framework\n",
    "\n",
    "Welcome to your custom deep learning framework! This notebook will guide you through the basics.\n",
    "\n",
    "## ðŸ“š What You'll Learn:\n",
    "- How to import and use the framework\n",
    "- Create your first neural network\n",
    "- Train on simple data\n",
    "- Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to path to import our deep learning framework\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from deep_learning import NeuralNetwork\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"âœ… All imports successful!\")\n",
    "print(\"ðŸ§  Deep Learning Framework loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Step 1: Create Some Sample Data\n",
    "\n",
    "Let's start with a simple binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple binary classification dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=500,\n",
    "    n_features=2,\n",
    "    n_redundant=0,\n",
    "    n_informative=2,\n",
    "    n_clusters_per_class=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Convert to our framework format\n",
    "y = (y + 1) // 2  # Convert from {-1, 1} to {0, 1}\n",
    "y = y.reshape(1, -1)  # Shape: (1, n_samples)\n",
    "X = X.T  # Shape: (n_features, n_samples)\n",
    "\n",
    "print(f\"ðŸ“Š Data shape: X = {X.shape}, y = {y.shape}\")\n",
    "print(f\"ðŸŽ¯ Classes: {np.unique(y)}\")\n",
    "\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = ['red' if label == 0 else 'blue' for label in y[0, :]]\n",
    "plt.scatter(X[0, :], X[1, :], c=colors, alpha=0.7, edgecolors='black')\n",
    "plt.title('ðŸ“Š Binary Classification Dataset')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ Step 2: Build Your Neural Network\n",
    "\n",
    "Now let's create and train a neural network using our framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X.T, y.T, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train, X_test = X_train.T, X_test.T\n",
    "y_train, y_test = y_train.T, y_test.T\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.T).T\n",
    "X_test = scaler.transform(X_test.T).T\n",
    "\n",
    "print(f\"ðŸ”„ Training data: {X_train.shape}\")\n",
    "print(f\"ðŸ”„ Test data: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the neural network\n",
    "model = NeuralNetwork(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# Add layers\n",
    "model.add_dense(units=8, activation='relu', input_size=2)\n",
    "model.add_dense(units=5, activation='relu')\n",
    "model.add_dense(units=1, activation='sigmoid')\n",
    "\n",
    "# Display the architecture\n",
    "print(\"ðŸ—ï¸ Neural Network Architecture:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ“ Step 3: Train the Model\n",
    "\n",
    "Time to train our neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"ðŸš€ Starting training...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 4: Evaluate and Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "train_loss, train_acc = model.evaluate(X_train, y_train)\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"ðŸ“ˆ Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"ðŸ“ˆ Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"ðŸ“‰ Training Loss: {train_loss:.4f}\")\n",
    "print(f\"ðŸ“‰ Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history['loss'], label='Training Loss', linewidth=2)\n",
    "plt.plot(history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "plt.title('ðŸ“‰ Training History - Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "plt.title('ðŸ“ˆ Training History - Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Test data visualization\n",
    "plt.subplot(1, 3, 3)\n",
    "colors = ['red' if label == 0 else 'blue' for label in y_test[0, :]]\n",
    "plt.scatter(X_test[0, :], X_test[1, :], c=colors, alpha=0.7, edgecolors='black')\n",
    "plt.title('ðŸŽ¯ Test Data Classification')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Step 5: Make Predictions\n",
    "\n",
    "Let's see how our model performs on new data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "binary_predictions = (predictions > 0.5).astype(int)\n",
    "\n",
    "print(f\"ðŸ”® Sample predictions (first 10):\")\n",
    "print(f\"Probabilities: {predictions[0, :10]}\")\n",
    "print(f\"Binary predictions: {binary_predictions[0, :10]}\")\n",
    "print(f\"True labels: {y_test[0, :10].astype(int)}\")\n",
    "\n",
    "# Calculate accuracy manually\n",
    "accuracy = np.mean(binary_predictions == y_test)\n",
    "print(f\"\\nâœ… Manual accuracy calculation: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
